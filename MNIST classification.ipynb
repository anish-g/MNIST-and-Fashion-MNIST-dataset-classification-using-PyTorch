{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset Classification using PyTorch step-by-step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST** dataset consists of greyscale handwritten digits. Each image is 28x28 pixels.\n",
    "<img src='assets/mnist.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Import requirements\n",
    "First, import **PyTorch**, its **nn** module to build network and datasets from **torchvision**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,), (0.5,))\n",
    "                               ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Build Forward Pass\n",
    "PyTorch provides a convinent way to build networks where a tensor is passed sequentially through operations with **nn.Sequential**\n",
    "This model returns the log-softmax as the output and calculates the loss using the negative log likelihood loss. *Note: for `nn.LogSoftmax`, the `dim` keyword argument has to be set appropriately. `dim=0` calculates softmax across the rows, so each column sums to 1, while `dim=1` calculates across the columns so each row sums to 1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3117, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Loss is generally assigned to keyword criterion\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Implementing Backward Pass\n",
    "Torch provides a module, `autograd`, for automatically calculating the gradients of tensors. It can be used to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, `requires_grad = True` should be set on a tensor. This can be done at creation with the `requires_grad` keyword, or at any time with `x.reuires_grad_(True)`.\n",
    "\n",
    "When a network is created with PyTorch, all of the parameters are initialized with `requires_grad = True`. This means that when the loss is calculated and `loss.backward()` is called, the gradients for the parameters are calculated. These gradients are used to update the weights with gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-1.7205e-04, -1.7205e-04, -1.7205e-04,  ..., -1.7205e-04,\n",
      "         -1.7205e-04, -1.7205e-04],\n",
      "        [-9.3246e-04, -9.3246e-04, -9.3246e-04,  ..., -9.3246e-04,\n",
      "         -9.3246e-04, -9.3246e-04],\n",
      "        [ 5.7061e-03,  5.7061e-03,  5.7061e-03,  ...,  5.7061e-03,\n",
      "          5.7061e-03,  5.7061e-03],\n",
      "        ...,\n",
      "        [ 9.9031e-05,  9.9031e-05,  9.9031e-05,  ...,  9.9031e-05,\n",
      "          9.9031e-05,  9.9031e-05],\n",
      "        [ 3.6040e-04,  3.6040e-04,  3.6040e-04,  ...,  3.6040e-04,\n",
      "          3.6040e-04,  3.6040e-04],\n",
      "        [ 1.3497e-03,  1.3497e-03,  1.3497e-03,  ...,  1.3497e-03,\n",
      "          1.3497e-03,  1.3497e-03]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Training Pass\n",
    "To start training, an optimizer is needed to update the weights with the gradients. These can be found in PyTorch's `optim` package. Stochastic gradient descent is used here with `optim.SGD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general process for one learning step with PyTorch is:\n",
    "* Make a forward pass through the network\n",
    "* Use the network output to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "When multiple backward passes are done with the same parameters, the gradients are accumulated. this means the gradients need to be zero on each training pass or the gradients from previous training batches is retained. The gradients is zeroed with `optimizer.zero_grad()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 1.4500e-02, -1.0694e-02, -5.0313e-03,  ...,  3.2782e-02,\n",
      "          4.0764e-03,  3.2388e-02],\n",
      "        [ 2.8190e-02,  2.4728e-02,  1.0211e-02,  ..., -1.4970e-02,\n",
      "          2.5396e-02, -5.2101e-03],\n",
      "        [-5.2342e-03, -2.4755e-05, -1.9817e-02,  ...,  1.5376e-02,\n",
      "          1.2489e-02,  2.1549e-02],\n",
      "        ...,\n",
      "        [-1.7510e-02,  1.2825e-02,  4.8500e-03,  ...,  2.6936e-02,\n",
      "         -1.0739e-02, -2.9443e-02],\n",
      "        [ 2.3936e-02, -1.7176e-02,  1.5411e-02,  ...,  9.5961e-04,\n",
      "          1.4006e-03, -1.7751e-03],\n",
      "        [-2.1720e-02, -8.5133e-03, -3.4115e-02,  ...,  6.8557e-03,\n",
      "          6.0177e-04,  1.0711e-02]], requires_grad=True)\n",
      "Gradient -  tensor([[ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n",
      "        [ 0.0024,  0.0024,  0.0024,  ...,  0.0024,  0.0024,  0.0024],\n",
      "        [ 0.0064,  0.0064,  0.0064,  ...,  0.0064,  0.0064,  0.0064],\n",
      "        ...,\n",
      "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [ 0.0004,  0.0004,  0.0004,  ...,  0.0004,  0.0004,  0.0004],\n",
      "        [ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023]])\n",
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 1.4494e-02, -1.0701e-02, -5.0381e-03,  ...,  3.2775e-02,\n",
      "          4.0696e-03,  3.2381e-02],\n",
      "        [ 2.8166e-02,  2.4704e-02,  1.0187e-02,  ..., -1.4994e-02,\n",
      "          2.5372e-02, -5.2338e-03],\n",
      "        [-5.2979e-03, -8.8484e-05, -1.9881e-02,  ...,  1.5312e-02,\n",
      "          1.2425e-02,  2.1485e-02],\n",
      "        ...,\n",
      "        [-1.7504e-02,  1.2830e-02,  4.8553e-03,  ...,  2.6941e-02,\n",
      "         -1.0733e-02, -2.9438e-02],\n",
      "        [ 2.3932e-02, -1.7180e-02,  1.5406e-02,  ...,  9.5541e-04,\n",
      "          1.3963e-03, -1.7793e-03],\n",
      "        [-2.1742e-02, -8.5360e-03, -3.4137e-02,  ...,  6.8330e-03,\n",
      "          5.7905e-04,  1.0688e-02]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "#Clear  the gradients as the gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient - ', model[0].weight.grad)\n",
    "\n",
    "# Update step and new weights\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Finally training the complete model\n",
    "One pass through the entire dataset is called an epoch. Here the model is looped through `trainloader` to get training batches. For each batch, a training pass is done where the loss is calculated, a backward pass is done, and the weights are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9536608488066618\n",
      "Training loss: 0.8544850124479103\n",
      "Training loss: 0.5129309449591108\n",
      "Training loss: 0.4235479667274428\n",
      "Training loss: 0.3822583086264413\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epoch = 5\n",
    "for e in range(epoch):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images. view(images.shape[0], -1)\n",
    "        \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check it's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "\n",
    "\n",
    "def view_classify(img, ps):\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
